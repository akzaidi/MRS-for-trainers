---
title: "Introduction to R"
author: "Ali Zaidi, Machine Learning and Data Science Education Team"
date: "April 26, 2016"
output:
  ioslides_presentation:
    logo: logo-130833979438186239.png
    smaller: yes
    widescreen: yes
  beamer_presentation: default
  slidy_presentation: default
transition: rotate
---

# Overview of the R Project

## Lesson Plan | R U Ready?

> - What the R Language for Statistical Computing is
> - R's capabilities and it's limitations
> - What types of problems you might want to use R with
> - How to manage data with open source R
> - How to develop models and write functions in R

## What is R? | Why should I care?

* R is a successor of the S Language, originated at Bell Labs AT&T
* Based on the Scheme interpreter
* Originally designed by two University of Auckland Professors for their introduction to statistics course

![Robert Gentleman and Ross Ihaka](http://revolution-computing.typepad.com/.a/6a010534b1db25970b016766fdae38970b-800wi)

## R Philosophy | What R Thou?

R follows the [Unix philosophy](http://en.wikipedia.org/wiki/Unix_philosophy)

> Write programs that do one thing and do it well. Write programs to work together.

> - R is extensible with more than 9,000 packages available at CRAN (http://crantastic.org/packages)
> - R, like it's inspiration, Scheme, is a functional programming language
> - R is lazy, and lazy evaluation can be used to interface to other languages
> - R is a highly interpreted dynamically typed language, allowing you to mutate variables and analyze datasets quickly, but is significantly slower than low-level, statically typed languages like C or Java
> - R has a high memory footprint, and can easily lead to crashes if you aren't careful

## Development Environments | Where to Write R Code

* The most popular integrated development environment for R is [RStudio](https://www.rstudio.com/)
* The RStudio IDE is entirely html/javascript based, so completely cross-platform
* RStudio Server for cloud instances
* Developers of RStudio have also written a plethora of useful R packages
* For Windows machines, we have recently announced the general availability of [R Tools for Visual Studio, RTVS](https://www.visualstudio.com/en-us/features/rtvs-vs.aspx)
* RTVS will support connectivity to Azure and SQL Server very soon
* RTVS has great debugging support

# Quick Tour of Your IDE

## Strengths of R | Where R Succeeds

* Expressive
* Open source 
* Extendable -- nearly 1000 packages with functions to use
* Focused on statistics and machine learning -- utilized by academics and practitioners
* Advanced data structures and graphical capabilities
* Large user community, academics and industry
* It is designed by statisticians 

## Weaknesses of R | Where R Falls Short

* It is designed by statisticians
* Inefficient at element-by-element computations
* May make large demands on system resources, namely memory
* Data capacity limited by memory
* Single-threaded

## Some Essential Open Source Packages

* There are over 1,000 R packages to choose from, what do I start with?
* Data Management: `dplyr`, `tidyr`, `data.table`
* Visualization: `ggplot2`, `ggvis`, `htmlwidgets`, `shiny`
* Data Importing: `haven`, `RODBC`
* Other favorites; `magrittr`, `rmarkdown`, `caret`

# R Foundations

## Command line prompts

Symbol | Meaning
------ | -------
  `>`   | ready for a new command
  `+`   | awaiting the completion of an existing command 

## I'm Lost! | Getting Help with R

* [Stack Overflow](http://stackoverflow.com/questions/tagged/r)
* [Cross Validated, R](http://stats.stackexchange.com/)
* [R Reference Card](https://cran.r-project.org/doc/contrib/Short-refcard.pdf)
* [RStudio Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)
* [R help mailing list and archives](https://stat.ethz.ch/mailman/listinfo/r-help)
* [CRAN Task Views](https://cran.r-project.org/web/views/)
* [Crantastic](http://crantastic.org/)
* [Revolutions Blog](http://blog.revolutionanalytics.com/)
* [R-Bloggers](http://www.r-bloggers.com/)

## Quick Tour of Things You Need to Know | Data Structures

* R's data structures can be described by their dimensionality, and their type.


|    | Homogeneous   | Heterogeneous |
|----|---------------|---------------|
| 1d | Atomic vector | List          |
| 2d | Matrix        | Data frame    |
| nd | Array         |               |

## Quick Tour of Things You Need to Know | Data Types

> - Atomic vectors come in one of four types
> - `logical` (boolean). Values: `TRUE` | `FALSE`
> - `integer`
> - `double` (often called numeric)
> - `character`
> - Rare types:
> - `complex` 
> - `raw`

# Lab 1: R Data Types

# Data Manipulation with the dplyr Package

## Overview

At the end of this session, you will have learned:

* How to manipulate data quickly with `dplyr` using a very intuitive 'grammar'
* How to use `dplyr` to perform common exploratory and manipulation procedures
* Apply your own custom functions to group manipulations `dplyr` with `mutate()`, `summarise()` and `do()`
* Connect to remote databases to work with larger than memory datasets

## Why use dplyr? | The Grammar of Data Manipulation

* R comes with a plethora of base functions for data manipulation
* `dplyr` makes data manipulation easier by providing a few functions for the most common tasks and procedures
* `dplyr` achieves remarkable speed-up gains by using a C++ backend
* `dplyr` has multiple backends for working with data stored in various sources: SQLite, MySQL, bigquery, and more
* `dplyr` was inspired to give data manipulation a simple, cohesive grammar (similar philosophy to `ggplot` - grammar of graphics)
* the recent package `dplyrXdf` brings much of the same functionality of `dplyr` to `XDF` data


## Manipulation verbs

filter

:    select rows based on matching criteria

slice

:    select rows by number

select

:    select columns by column names

arrange

:    reorder rows by column values

mutate

:    add new variables based on transformations of existing variables

transmute

:    transform and drop other variables



## Aggregation verbs

group_by

:    identify grouping variables for calculating groupwise summary statistics


count

:    count the number of records per group


summarise

:    calculate one or more summary functions per group, returning one row of results per group (or one for the entire dataset)

## Viewing Data

* `dplyr` includes a wrapper called `tbl_df` makes df into a 'local df' that improves the printing of dataframes in the console
* if you want to see more of the data you can still coerce to `data.frame`

```{rdf, message = FALSE}
library(dplyr)
bankData <- read.table("data/bank-full.csv",
                       header = T, sep = ";",
                       stringsAsFactors = F)
(bankData <- tbl_df(bankData))
```

# Filtering and Reordering Data

## Subsetting Data

* `dplyr` makes subsetting by rows very easy
* The `filter` verb takes conditions for filtering rows based on conditions

```{rfilter1}
filter(bankData,
       month %in% c("april", "may", "jun"), 
       default == "yes")
```

## Exercise

Your turn: 

* How many defaults in the dataset?
* How many of the entrepeneurs that defaulted were also divorced?

## Solution

```{r ex-agg-soln1, opts.label="solution"}
defaults <- filter(bankData, default == "yes")
nrow(defaults)
brokeEntrepreneurs <- filter(bankData, 
                             job == "entrepreneur", 
                             marital == "divorced", 
                             default == "yes")
nrow(brokeEntrepreneurs)
```

## Select a set of columns

* You can use the `select()` verb to specify which columns of a dataset you want
* This is similar to the `keep` option in SAS's data step.
* Use a colon `:` to select all the columns between two variables (inclusive)
* Use `contains` to take any columns containing a certain word/phrase/character

## Select Example 1

```{rselect1}
select(bankData, age, job, default, balance, housing)
```

## Select: Other Options

starts_with(x, ignore.case = FALSE)

:    name starts with `x`

ends_with(x, ignore.case = FALSE)

:    name ends with `x`

matches(x, ignore.case = FALSE)

:    selects all variables whose name matches the regular expression `x`

num_range("V", 1:5, width = 1)

:    selects all variables (numerically) from `V1` to `V5`.

You can also use a `-` to drop variables.

## Reordering Data

* You can reorder your dataset based on conditions using the `arrange()` verb

```{rarrange2}
arrange(bankData, balance, default)
```

## Exercise

Use `arrange()` to  sort on the basis of `y`, `marital`, `job` (in descending order), and `balance`

## Solution

```{r arrange-exc}
arrange(bankData, y, marital, desc(job), balance)
```

## Summary

filter

:    Extract subsets of rows. See also `slice()`

select

:    Extract subsets of columns. See also `rename()`

arrange

:    Sort your data

## Transformations

* The `mutate()` verb can be used to make new columns

```{rmutate1}
mutate(bankData,
       DefaultFlag = ifelse(default == 'yes',
                              yes =  1,
                              no = 0)
)
```

## Summarise Data by Groups

* The `group_by` verb creates a grouping by a categorical variable
* Functions can be placed inside `summarise` to create summary functions

```{rsummarise}
summarise(group_by(bankData, default), Num = n())
```

## Example group_by 2

```{rsummarise2}
summarise(group_by(bankData, default), ave_balance = mean(balance))
```

## Example group_by 3

```{rsummarise3}
summarise(group_by(bankData, default),
          ave_balance = mean(balance),
          num = n()
)
```

## Chaining/Piping

* A `dplyr` installation includes the `magrittr` package as a dependency 
* The `magrittr` package includes a pipe operator that allows you to pass the current dataset to another function
* This makes interpreting a nested sequence of operations much easier to understand

## Standard Code

Code is executed inside-out.

```{rinsideout}
arrange(filter(select(bankData, age, job, education, default), default == 'yes'), job, education, age)
```

## Reformatted


```{rformatinsideout}
arrange(
  filter(
    select(bankData, age, job, education, default), 
    default == 'yes'), 
  job, education, age)
```

## With Piping

```{rpiping}
bankData %>% 
  select(age, job, education, default) %>%
  filter(default == 'yes') %>%
  arrange(job, education, age)
```


## Pipe + group_by()

The pipe operator is very helpful for group by summaries

```{rgroupsum}
bankData %>% 
  group_by(job) %>%
  summarise(num = n(),
            ave_balance = mean(balance),
            num_defaults = sum(default == 'yes'),
            default_rate = num_defaults/num)
```

## Pipe and Plot

As a reminder, piping can also be used for non-dplyr functions.

```{rpipeplot, fig.height = 3}
library(ggplot2)
bankData %>% 
  filter(job %in% c("management", "technician", "unemployed")) %>%
  group_by(job, marital) %>% 
  summarise(Counts = n()) %>% 
  ggplot() + 
  geom_bar(aes(x = job, y = Counts, fill = marital),
           stat = 'identity', position = 'dodge')

```

## Exercise
  
Your turn: 

* Use the pipe operator to group by job and housing status
* Calculate the counts of observations, and the average and median balance

## Solution

```{r ex-pipe-soln}
bankData %>% 
  group_by(job, housing) %>%
  summarise(Counts = n(),
            average_balance = mean(as.numeric(balance)),
            median_balance = median(as.numeric(balance)))
```

## Summary

mutate

:    Create transformations

summarise

:    Aggregate

group_by

:    Group your dataset by levels

distinct

:    Extract unique values (frequently used with `arrange()`)

Chaining with the `%>%` operator can result in more readable code.



## Thanks for Attending!

- Any questions?
- [alizaidi@microsoft.com](mailto:alizaidi@microsoft.com)